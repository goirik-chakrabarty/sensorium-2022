{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# How to train the Baseline Models for the SENSORIUM track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### This notebook will show how to\n",
    "- instantiate dataloader for the Sensorium track\n",
    "- instantiate pytorch model\n",
    "- instantiate a trainer function\n",
    "- train two baselines for this competition track\n",
    "- save the model weights (the model weights can already be found in './model_checkpoints/pretrained/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from nnfabrik.builder import get_data, get_model, get_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Instantiate DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# loading the SENSORIUM dataset\n",
    "filenames = ['../data/static26872-17-20-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip', ]\n",
    "\n",
    "dataset_fn = 'sensorium.datasets.static_loaders'\n",
    "dataset_config = {'paths': filenames,\n",
    "                 'normalize': True,\n",
    "                 'include_behavior': False,\n",
    "                 'include_eye_position': False,\n",
    "                 'batch_size': 128,\n",
    "                 'scale':0.25,\n",
    "                 }\n",
    "\n",
    "dataloaders = get_data(dataset_fn, dataset_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Instantiate State of the Art Model (SOTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fn = 'sensorium.models.stacked_core_full_gauss_readout'\n",
    "model_config = {'pad_input': False,\n",
    "  'stack': -1,\n",
    "  'layers': 4,\n",
    "  'input_kern': 9,\n",
    "  'gamma_input': 6.3831,\n",
    "  'gamma_readout': 0.0076,\n",
    "  'hidden_kern': 7,\n",
    "  'hidden_channels': 64,\n",
    "  'depth_separable': True,\n",
    "  'grid_mean_predictor': {'type': 'cortex',\n",
    "   'input_dimensions': 2,\n",
    "   'hidden_layers': 1,\n",
    "   'hidden_features': 30,\n",
    "   'final_tanh': True},\n",
    "  'init_sigma': 0.1,\n",
    "  'init_mu_range': 0.3,\n",
    "  'gauss_type': 'full',\n",
    "  'shifter': False,\n",
    "}\n",
    "\n",
    "model = get_model(model_fn=model_fn,\n",
    "                  model_config=model_config,\n",
    "                  dataloaders=dataloaders,\n",
    "                  seed=42,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Configure Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer_fn = \"sensorium.training.standard_trainer\"\n",
    "\n",
    "trainer_config = {'max_iter': 200,\n",
    "                 'verbose': False,\n",
    "                 'lr_decay_steps': 4,\n",
    "                 'avg_loss': False,\n",
    "                 'lr_init': 0.009,\n",
    "                 }\n",
    "\n",
    "trainer = get_trainer(trainer_fn=trainer_fn, \n",
    "                     trainer_config=trainer_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Run model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 35/35 [00:02<00:00, 11.98it/s]\n",
      "Epoch 2: 100%|██████████| 35/35 [00:02<00:00, 11.82it/s]\n",
      "Epoch 3:  34%|███▍      | 12/35 [00:01<00:02, 11.23it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0091e0ba0fd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidation_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/project/sensorium/training/trainers.py\u001b[0m in \u001b[0;36mstandard_trainer\u001b[0;34m(model, dataloaders, seed, avg_loss, scale_loss, loss_function, stop_function, loss_accum_batch_n, device, verbose, interval, patience, epoch, lr_init, max_iter, maximize, tolerance, restore_best, lr_decay_steps, lr_decay_factor, min_lr, cb, track_training, detach_core, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# train over batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         for batch_no, (data_key, data) in tqdm(\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLongCycler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/neuralpredictors/training/cyclers.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         ):\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/neuralpredictors/training/cyclers.py\u001b[0m in \u001b[0;36mcycle\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/neuralpredictors/data/datasets/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# ensure only specified types of transforms are used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;31m# apply output rename if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/neuralpredictors/data/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0mkey_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey_vals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m         key_vals[self.in_name] = rescale(\n\u001b[0m\u001b[1;32m    510\u001b[0m             \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/skimage/_shared/utils.py\u001b[0m in \u001b[0;36mfixed_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;31m# Call the function with the fixed arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultichannel_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_axis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mrescale\u001b[0;34m(image, scale, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma, channel_axis)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0moutput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     return resize(image, output_shape, order=order, mode=mode, cval=cval,\n\u001b[0m\u001b[1;32m    290\u001b[0m                   \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreserve_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                   \u001b[0manti_aliasing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manti_aliasing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0mzoom_factors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     out = ndi.zoom(filtered, zoom_factors, order=order, mode=ndi_mode,\n\u001b[0m\u001b[1;32m    186\u001b[0m                    cval=cval, grid_mode=True)\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/ndimage/_interpolation.py\u001b[0m in \u001b[0;36mzoom\u001b[0;34m(input, zoom, output, order, mode, cval, prefilter, grid_mode)\u001b[0m\n\u001b[1;32m    817\u001b[0m                         where=zoom_div != 0)\n\u001b[1;32m    818\u001b[0m     \u001b[0mzoom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzoom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m     _nd_image.zoom_shift(filtered, zoom, None, output, order, mode, cval, npad,\n\u001b[0m\u001b[1;32m    820\u001b[0m                          grid_mode)\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "validation_score, trainer_output, state_dict = trainer(model, dataloaders, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save model checkpoints after training is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './model_checkpoints/sensorium_sota_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Model Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_def = torch.load('./model_checkpoints/sensorium_sota_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_def = torch.load('./model_checkpoints/pretrained/sensorium_sota_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'core.features.layer1.ds_conv.in_depth_conv.bias',\n",
       " 'core.features.layer1.ds_conv.out_depth_conv.bias',\n",
       " 'core.features.layer1.ds_conv.spatial_conv.bias',\n",
       " 'core.features.layer2.ds_conv.in_depth_conv.bias',\n",
       " 'core.features.layer2.ds_conv.out_depth_conv.bias',\n",
       " 'core.features.layer2.ds_conv.spatial_conv.bias',\n",
       " 'core.features.layer3.ds_conv.in_depth_conv.bias',\n",
       " 'core.features.layer3.ds_conv.out_depth_conv.bias',\n",
       " 'core.features.layer3.ds_conv.spatial_conv.bias'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list(new_def.keys())).difference(set(list(old_def.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list(old_def.keys())).difference(set(list(new_def.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for FiringRateEncoder:\n\tMissing key(s) in state_dict: \"core.features.layer1.ds_conv.in_depth_conv.bias\", \"core.features.layer1.ds_conv.spatial_conv.bias\", \"core.features.layer1.ds_conv.out_depth_conv.bias\", \"core.features.layer2.ds_conv.in_depth_conv.bias\", \"core.features.layer2.ds_conv.spatial_conv.bias\", \"core.features.layer2.ds_conv.out_depth_conv.bias\", \"core.features.layer3.ds_conv.in_depth_conv.bias\", \"core.features.layer3.ds_conv.spatial_conv.bias\", \"core.features.layer3.ds_conv.out_depth_conv.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2bda7357b599>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./model_checkpoints/pretrained/sensorium_sota_model.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1052\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1053\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for FiringRateEncoder:\n\tMissing key(s) in state_dict: \"core.features.layer1.ds_conv.in_depth_conv.bias\", \"core.features.layer1.ds_conv.spatial_conv.bias\", \"core.features.layer1.ds_conv.out_depth_conv.bias\", \"core.features.layer2.ds_conv.in_depth_conv.bias\", \"core.features.layer2.ds_conv.spatial_conv.bias\", \"core.features.layer2.ds_conv.out_depth_conv.bias\", \"core.features.layer3.ds_conv.in_depth_conv.bias\", \"core.features.layer3.ds_conv.spatial_conv.bias\", \"core.features.layer3.ds_conv.out_depth_conv.bias\". "
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./model_checkpoints/pretrained/sensorium_sota_model.pth\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"./model_checkpoints/sensorium_sota_model.pth\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29481468"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train a simple LN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Our LN model has the same architecture as our CNN model (a convolutional core followed by a gaussian readout)\n",
    "but with all non-linearities removed except the final ELU+1 nonlinearity.\n",
    "Thus turning the CNN model effectively into a fully linear model followed by a single output non-linearity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fn = 'sensorium.models.stacked_core_full_gauss_readout'\n",
    "model_config = {'pad_input': False,\n",
    "              'stack': -1,\n",
    "              'layers': 3,\n",
    "              'input_kern': 9,\n",
    "              'gamma_input': 6.3831,\n",
    "              'gamma_readout': 0.0076,\n",
    "              'hidden_kern': 7,\n",
    "              'hidden_channels': 64,\n",
    "              'grid_mean_predictor': {'type': 'cortex',\n",
    "              'input_dimensions': 2,\n",
    "              'hidden_layers': 1,\n",
    "              'hidden_features': 30,\n",
    "              'final_tanh': True},\n",
    "              'depth_separable': True,\n",
    "              'init_sigma': 0.1,\n",
    "              'init_mu_range': 0.3,\n",
    "              'gauss_type': 'full',\n",
    "              'linear': True\n",
    "               }\n",
    "model = get_model(model_fn=model_fn,\n",
    "                  model_config=model_config,\n",
    "                  dataloaders=dataloaders,\n",
    "                  seed=42,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 35/35 [00:02<00:00, 13.20it/s]\n",
      "Epoch 2: 100%|██████████| 35/35 [00:02<00:00, 13.36it/s]\n",
      "Epoch 3: 100%|██████████| 35/35 [00:02<00:00, 13.40it/s]\n",
      "Epoch 4: 100%|██████████| 35/35 [00:02<00:00, 13.39it/s]\n",
      "Epoch 5: 100%|██████████| 35/35 [00:02<00:00, 13.22it/s]\n",
      "Epoch 6: 100%|██████████| 35/35 [00:02<00:00, 12.94it/s]\n",
      "Epoch 7: 100%|██████████| 35/35 [00:02<00:00, 13.14it/s]\n",
      "Epoch 8: 100%|██████████| 35/35 [00:02<00:00, 13.37it/s]\n",
      "Epoch 9: 100%|██████████| 35/35 [00:02<00:00, 13.40it/s]\n",
      "Epoch 10: 100%|██████████| 35/35 [00:02<00:00, 13.37it/s]\n",
      "Epoch 11: 100%|██████████| 35/35 [00:02<00:00, 13.37it/s]\n",
      "Epoch 12: 100%|██████████| 35/35 [00:02<00:00, 13.29it/s]\n",
      "Epoch 13: 100%|██████████| 35/35 [00:02<00:00, 13.24it/s]\n",
      "Epoch 14: 100%|██████████| 35/35 [00:02<00:00, 13.26it/s]\n",
      "Epoch 15: 100%|██████████| 35/35 [00:02<00:00, 12.90it/s]\n",
      "Epoch 16: 100%|██████████| 35/35 [00:02<00:00, 13.24it/s]\n",
      "Epoch 17: 100%|██████████| 35/35 [00:02<00:00, 13.22it/s]\n",
      "Epoch 18: 100%|██████████| 35/35 [00:02<00:00, 13.22it/s]\n",
      "Epoch 19: 100%|██████████| 35/35 [00:02<00:00, 13.20it/s]\n",
      "Epoch 20: 100%|██████████| 35/35 [00:02<00:00, 13.21it/s]\n",
      "Epoch 21: 100%|██████████| 35/35 [00:02<00:00, 13.21it/s]\n",
      "Epoch 22: 100%|██████████| 35/35 [00:02<00:00, 13.21it/s]\n",
      "Epoch 23: 100%|██████████| 35/35 [00:02<00:00, 12.73it/s]\n",
      "Epoch 24: 100%|██████████| 35/35 [00:02<00:00, 12.49it/s]\n",
      "Epoch 25: 100%|██████████| 35/35 [00:02<00:00, 12.36it/s]\n",
      "Epoch 26: 100%|██████████| 35/35 [00:02<00:00, 13.17it/s]\n",
      "Epoch 27: 100%|██████████| 35/35 [00:02<00:00, 12.93it/s]\n",
      "Epoch 28: 100%|██████████| 35/35 [00:02<00:00, 12.64it/s]\n",
      "Epoch 29: 100%|██████████| 35/35 [00:02<00:00, 13.22it/s]\n",
      "Epoch 30: 100%|██████████| 35/35 [00:02<00:00, 13.20it/s]\n",
      "Epoch 31: 100%|██████████| 35/35 [00:02<00:00, 13.22it/s]\n",
      "Epoch 32: 100%|██████████| 35/35 [00:02<00:00, 13.10it/s]\n",
      "Epoch 33: 100%|██████████| 35/35 [00:02<00:00, 12.41it/s]\n",
      "Epoch 34: 100%|██████████| 35/35 [00:02<00:00, 12.93it/s]\n",
      "Epoch 35: 100%|██████████| 35/35 [00:02<00:00, 12.50it/s]\n",
      "Epoch 36: 100%|██████████| 35/35 [00:02<00:00, 13.16it/s]\n",
      "Epoch 37: 100%|██████████| 35/35 [00:02<00:00, 12.79it/s]\n",
      "Epoch 38: 100%|██████████| 35/35 [00:02<00:00, 12.56it/s]\n",
      "Epoch 39: 100%|██████████| 35/35 [00:02<00:00, 13.16it/s]\n",
      "Epoch 40: 100%|██████████| 35/35 [00:02<00:00, 13.17it/s]\n",
      "Epoch 41: 100%|██████████| 35/35 [00:02<00:00, 13.18it/s]\n",
      "Epoch 42: 100%|██████████| 35/35 [00:02<00:00, 13.03it/s]\n",
      "Epoch 43: 100%|██████████| 35/35 [00:02<00:00, 12.48it/s]\n",
      "Epoch 44: 100%|██████████| 35/35 [00:02<00:00, 13.10it/s]\n",
      "Epoch 45: 100%|██████████| 35/35 [00:02<00:00, 13.15it/s]\n",
      "Epoch 46: 100%|██████████| 35/35 [00:02<00:00, 12.83it/s]\n",
      "Epoch 47: 100%|██████████| 35/35 [00:02<00:00, 13.19it/s]\n",
      "Epoch 48: 100%|██████████| 35/35 [00:02<00:00, 13.20it/s]\n",
      "Epoch 49: 100%|██████████| 35/35 [00:02<00:00, 13.18it/s]\n",
      "Epoch 50: 100%|██████████| 35/35 [00:02<00:00, 13.16it/s]\n",
      "Epoch 51: 100%|██████████| 35/35 [00:02<00:00, 13.19it/s]\n",
      "Epoch 52: 100%|██████████| 35/35 [00:02<00:00, 13.19it/s]\n",
      "Epoch 53: 100%|██████████| 35/35 [00:02<00:00, 12.80it/s]\n",
      "Epoch 54: 100%|██████████| 35/35 [00:02<00:00, 12.70it/s]\n",
      "Epoch 55: 100%|██████████| 35/35 [00:02<00:00, 12.70it/s]\n",
      "Epoch 56: 100%|██████████| 35/35 [00:02<00:00, 12.93it/s]\n",
      "Epoch 57: 100%|██████████| 35/35 [00:02<00:00, 13.11it/s]\n",
      "Epoch 58: 100%|██████████| 35/35 [00:02<00:00, 12.46it/s]\n",
      "Epoch 59: 100%|██████████| 35/35 [00:02<00:00, 13.18it/s]\n",
      "Epoch 60: 100%|██████████| 35/35 [00:02<00:00, 13.23it/s]\n",
      "Epoch 61: 100%|██████████| 35/35 [00:02<00:00, 13.25it/s]\n",
      "Epoch 62: 100%|██████████| 35/35 [00:02<00:00, 13.18it/s]\n",
      "Epoch 63: 100%|██████████| 35/35 [00:02<00:00, 12.58it/s]\n",
      "Epoch 64: 100%|██████████| 35/35 [00:02<00:00, 12.91it/s]\n",
      "Epoch 65: 100%|██████████| 35/35 [00:02<00:00, 12.44it/s]\n",
      "Epoch 66: 100%|██████████| 35/35 [00:02<00:00, 13.12it/s]\n",
      "Epoch 67: 100%|██████████| 35/35 [00:02<00:00, 12.98it/s]\n",
      "Epoch 68: 100%|██████████| 35/35 [00:02<00:00, 12.60it/s]\n",
      "Epoch 69: 100%|██████████| 35/35 [00:02<00:00, 13.09it/s]\n",
      "Epoch 70: 100%|██████████| 35/35 [00:02<00:00, 13.17it/s]\n",
      "Epoch 71: 100%|██████████| 35/35 [00:02<00:00, 13.19it/s]\n",
      "Epoch 72: 100%|██████████| 35/35 [00:02<00:00, 13.12it/s]\n",
      "Epoch 73: 100%|██████████| 35/35 [00:02<00:00, 12.53it/s]\n",
      "Epoch 74: 100%|██████████| 35/35 [00:02<00:00, 13.08it/s]\n",
      "Epoch 75: 100%|██████████| 35/35 [00:02<00:00, 13.22it/s]\n",
      "Epoch 76: 100%|██████████| 35/35 [00:02<00:00, 13.25it/s]\n",
      "Epoch 77: 100%|██████████| 35/35 [00:02<00:00, 12.88it/s]\n",
      "Epoch 78: 100%|██████████| 35/35 [00:02<00:00, 13.20it/s]\n",
      "Epoch 79: 100%|██████████| 35/35 [00:02<00:00, 13.19it/s]\n",
      "Epoch 80: 100%|██████████| 35/35 [00:02<00:00, 13.23it/s]\n",
      "Epoch 81: 100%|██████████| 35/35 [00:02<00:00, 13.21it/s]\n",
      "Epoch 82: 100%|██████████| 35/35 [00:02<00:00, 13.17it/s]\n",
      "Epoch 83: 100%|██████████| 35/35 [00:02<00:00, 12.88it/s]\n",
      "Epoch 84: 100%|██████████| 35/35 [00:02<00:00, 12.77it/s]\n",
      "Epoch 85: 100%|██████████| 35/35 [00:02<00:00, 13.13it/s]\n",
      "Epoch 86: 100%|██████████| 35/35 [00:02<00:00, 13.22it/s]\n",
      "Epoch 87: 100%|██████████| 35/35 [00:02<00:00, 13.21it/s]\n",
      "Epoch 88: 100%|██████████| 35/35 [00:02<00:00, 13.21it/s]\n",
      "Epoch 89: 100%|██████████| 35/35 [00:02<00:00, 13.22it/s]\n",
      "Epoch 90: 100%|██████████| 35/35 [00:02<00:00, 13.22it/s]\n",
      "Epoch 91: 100%|██████████| 35/35 [00:02<00:00, 13.22it/s]\n",
      "Epoch 92: 100%|██████████| 35/35 [00:02<00:00, 13.16it/s]\n",
      "Epoch 93: 100%|██████████| 35/35 [00:02<00:00, 13.09it/s]\n",
      "Epoch 94: 100%|██████████| 35/35 [00:02<00:00, 13.16it/s]\n",
      "Epoch 95: 100%|██████████| 35/35 [00:02<00:00, 13.16it/s]\n",
      "Epoch 96: 100%|██████████| 35/35 [00:02<00:00, 13.15it/s]\n",
      "Epoch 97: 100%|██████████| 35/35 [00:02<00:00, 13.14it/s]\n",
      "Epoch 98: 100%|██████████| 35/35 [00:02<00:00, 13.15it/s]\n",
      "Epoch 99: 100%|██████████| 35/35 [00:02<00:00, 13.14it/s]\n",
      "Epoch 100: 100%|██████████| 35/35 [00:02<00:00, 13.15it/s]\n",
      "Epoch 101: 100%|██████████| 35/35 [00:02<00:00, 13.08it/s]\n",
      "Epoch 102: 100%|██████████| 35/35 [00:04<00:00,  8.47it/s]\n",
      "Epoch 103: 100%|██████████| 35/35 [00:03<00:00, 10.21it/s]\n",
      "Epoch 104: 100%|██████████| 35/35 [00:03<00:00, 10.22it/s]\n",
      "Epoch 105: 100%|██████████| 35/35 [00:03<00:00,  9.85it/s]\n",
      "Epoch 106: 100%|██████████| 35/35 [00:03<00:00,  9.59it/s]\n",
      "Epoch 107: 100%|██████████| 35/35 [00:03<00:00, 10.01it/s]\n",
      "Epoch 108: 100%|██████████| 35/35 [00:03<00:00, 10.19it/s]\n",
      "Epoch 109: 100%|██████████| 35/35 [00:03<00:00,  9.89it/s]\n",
      "Epoch 110: 100%|██████████| 35/35 [00:03<00:00,  9.72it/s]\n"
     ]
    }
   ],
   "source": [
    "validation_score, trainer_output, state_dict = trainer(model, dataloaders, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './model_checkpoints/sensorium_ln_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20398675"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"./model_checkpoints/pretrained/sensorium_ln_model.pth\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
